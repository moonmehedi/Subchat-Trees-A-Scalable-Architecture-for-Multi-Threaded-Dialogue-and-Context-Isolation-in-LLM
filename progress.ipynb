{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76b2e836",
   "metadata": {},
   "source": [
    "Perfect! I can see you have a small typo in your message.py file (`Feild` should be `Field`), but more importantly, I've read through your complete implementation in the notebook. \n",
    "\n",
    "Let me first understand what you've already built and then create a **step-by-step roadmap** to implement this in FastAPI.\n",
    "\n",
    "## üéØ **What You've Already Built (From Notebook Analysis)**\n",
    "\n",
    "You have a **complete hierarchical chat system** with:\n",
    "\n",
    "1. **Core Components:**\n",
    "   - `LocalBuffer` - Fixed-size message queue per node\n",
    "   - `TreeNode` - Hierarchical conversation nodes\n",
    "   - `ChatGraphManager` - Manages nodes within a tree\n",
    "   - `Forest` - Manages multiple conversation trees\n",
    "   - `GlobalVectorIndex` - Semantic search with ChromaDB\n",
    "   - `LLMClient` - LLM communication\n",
    "   - `ChatAssembler` - Main orchestrator\n",
    "\n",
    "2. **Key Features:**\n",
    "   - Context isolation per conversation thread\n",
    "   - Parent-child memory inheritance\n",
    "   - Vector search for relevant context retrieval\n",
    "   - CLI interface with tree navigation\n",
    "\n",
    "## üìã **Step-by-Step Implementation Roadmap**\n",
    "\n",
    "### **Phase 1: Foundation (Steps 1-3)**\n",
    "- ‚úÖ **Step 1:** Basic setup (DONE)\n",
    "- üîÑ **Step 2:** Core data models (CURRENT - fix Message model)\n",
    "- **Step 3:** TreeNode and basic tree structure\n",
    "\n",
    "### **Phase 2: Core Logic (Steps 4-6)**\n",
    "- **Step 4:** LocalBuffer implementation\n",
    "- **Step 5:** ChatGraphManager and Forest\n",
    "- **Step 6:** Basic FastAPI endpoints for tree operations\n",
    "\n",
    "### **Phase 3: AI Integration (Steps 7-9)**\n",
    "- **Step 7:** LLM Client integration\n",
    "- **Step 8:** Vector store setup (ChromaDB)\n",
    "- **Step 9:** ChatAssembler orchestrator\n",
    "\n",
    "### **Phase 4: API & Testing (Steps 10-12)**\n",
    "- **Step 10:** Complete REST API endpoints\n",
    "- **Step 11:** Frontend integration points\n",
    "- **Step 12:** Testing and refinement\n",
    "\n",
    "---\n",
    "\n",
    "## **STEP 2 (CURRENT): Fix Message Model**\n",
    "\n",
    "First, let's fix your message.py file:\n",
    "\n",
    "````python\n",
    "from pydantic import BaseModel, Field  # Fixed: Field not Feild\n",
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "class Message(BaseModel):\n",
    "    id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n",
    "    content: str\n",
    "    role: str  # 'user' or 'assistant'\n",
    "    timestamp: datetime = Field(default_factory=datetime.now)\n",
    "    node_id: str\n",
    "    \n",
    "    class Config:\n",
    "        json_encoders = {\n",
    "            datetime: lambda v: v.isoformat()\n",
    "        }\n",
    "\n",
    "class MessageCreate(BaseModel):\n",
    "    content: str\n",
    "    role: str\n",
    "    node_id: str\n",
    "\n",
    "class MessageResponse(BaseModel):\n",
    "    id: str\n",
    "    content: str\n",
    "    role: str\n",
    "    timestamp: datetime\n",
    "    node_id: str\n",
    "````\n",
    "\n",
    "**Test it:**\n",
    "\n",
    "````python\n",
    "from src.models.message import Message, MessageCreate\n",
    "\n",
    "def test_message_model():\n",
    "    print(\"Testing Message model...\")\n",
    "    \n",
    "    message = Message(\n",
    "        content=\"Hello, this is a test message!\",\n",
    "        role=\"user\", \n",
    "        node_id=\"test-node-123\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Message ID: {message.id}\")\n",
    "    print(f\"‚úÖ Content: {message.content}\")\n",
    "    print(f\"‚úÖ Role: {message.role}\")\n",
    "    print(f\"‚úÖ Timestamp: {message.timestamp}\")\n",
    "    print(f\"‚úÖ Node ID: {message.node_id}\")\n",
    "    print(\"‚úÖ Message model working!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_message_model()\n",
    "````\n",
    "\n",
    "**Your Task:**\n",
    "1. Fix the typo in message.py (`Feild` ‚Üí `Field`)\n",
    "2. Add the complete Message model code\n",
    "3. Create and run the test: `python test_message.py`\n",
    "\n",
    "**Once this works, we'll move to Step 3: TreeNode model** - which is the core of your hierarchical structure.\n",
    "\n",
    "**Question:** Ready to fix the Message model and move forward with this roadmap?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a963848",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052a196",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "yes lets move to front-end integration i already have a frontend folder containing the frot end which already has a follow up button and all logic that i want \n",
    "\n",
    "\n",
    "okay now i would give you a short description what i expect from the front-end \n",
    "\n",
    "if the user send message ai response normally but if he click followup button a new node created you know something like that\n",
    "\n",
    "so lets do it lets start with the simple query and response suppose i am sending a question and the ai is responding based on that question\n",
    "\n",
    "like the simple chat and reponse lets do it first\n",
    "\n",
    "and about title it will be generated automatically when first question in that node is asked you know"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cc41d8",
   "metadata": {},
   "source": [
    "# üìä **FRONTEND ANALYSIS COMPLETE!**\n",
    "\n",
    "## ‚úÖ **Your Existing Frontend Architecture**\n",
    "\n",
    "Perfect! I've read through your entire frontend structure. You have a **sophisticated chat system** already built with excellent architecture:\n",
    "\n",
    "### **üèóÔ∏è Core Architecture:**\n",
    "- **Next.js 15** with TypeScript + Tailwind CSS\n",
    "- **shadcn/ui** components for modern UI\n",
    "- **Hierarchical chat sessions** with parent-child relationships\n",
    "- **Chat carousel** for viewing multiple conversations\n",
    "- **Follow-up button** with text selection + subchat creation\n",
    "\n",
    "### **üéØ Key Components Found:**\n",
    "\n",
    "#### **1. Main App Logic (`src/app/page.tsx`):**\n",
    "- ‚úÖ **ChatSession management** with parent/child relationships  \n",
    "- ‚úÖ **Branch navigation** (`getBranchForChat`) - hierarchical logic\n",
    "- ‚úÖ **Follow-up creation** (`handleRelatedTopicClick`) - creates child chats\n",
    "- ‚úÖ **Auto-title generation** from first message\n",
    "- ‚úÖ **Chat carousel** for side-by-side conversation viewing\n",
    "\n",
    "#### **2. Follow-up Button (`src/components/chat/follow-up-prompt.tsx`):**\n",
    "- ‚úÖ **Text selection** with mouse-up detection\n",
    "- ‚úÖ **Popover positioning** for \"Ask InsightFlow\" button\n",
    "- ‚úÖ **Dynamic subchat creation** from selected text\n",
    "\n",
    "#### **3. API Layer (`src/app/actions.ts`):**\n",
    "- ‚úÖ **getAiResponse()** - currently using Genkit/Gemini\n",
    "- ‚úÖ **getAiTitle()** - auto-generates chat titles\n",
    "- ‚úÖ **Server actions** ready for backend integration\n",
    "\n",
    "#### **4. Current AI Integration:**\n",
    "- ‚úÖ **Genkit flows** for chat responses + title generation\n",
    "- ‚úÖ **Related topics** suggestion\n",
    "- ‚úÖ **Web search tool** (placeholder)\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ **Integration Strategy: Your Frontend ‚Üí Our Backend**\n",
    "\n",
    "### **What Needs to Change:**\n",
    "1. **Replace AI calls** in `actions.ts` to use your hierarchical backend API\n",
    "2. **Update API client** to call `localhost:8000/api/*` endpoints  \n",
    "3. **Map frontend ChatSession** to backend TreeNode structure\n",
    "4. **Connect follow-up button** to backend subchat creation\n",
    "\n",
    "### **What Stays the Same:**\n",
    "- ‚úÖ All UI components (perfect as-is!)\n",
    "- ‚úÖ Chat carousel and navigation logic\n",
    "- ‚úÖ Follow-up button and text selection\n",
    "- ‚úÖ Hierarchical session management\n",
    "- ‚úÖ Auto-title generation flow\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ **Next Steps: Simple Integration**\n",
    "\n",
    "Since you want to **start simple** with basic chat + response, here's the plan:\n",
    "\n",
    "### **Step 1: Replace getAiResponse() in actions.ts**\n",
    "```typescript\n",
    "// OLD: Genkit call\n",
    "const aiResponse = await generateChatbotResponse({ prompt: userInput });\n",
    "\n",
    "// NEW: Your backend API\n",
    "const response = await fetch('http://localhost:8000/api/conversations/[id]/messages', {\n",
    "  method: 'POST',\n",
    "  body: JSON.stringify({ message: userInput })\n",
    "});\n",
    "```\n",
    "\n",
    "### **Step 2: Update handleRelatedTopicClick() for Subchats**\n",
    "```typescript\n",
    "// Creates subchat via your backend API instead of local state\n",
    "const subchatResponse = await fetch('http://localhost:8000/api/conversations/[parent-id]/subchats', {\n",
    "  method: 'POST', \n",
    "  body: JSON.stringify({ title: titleResponse.title })\n",
    "});\n",
    "```\n",
    "\n",
    "**Your frontend architecture is EXCELLENT and ready for integration!** üéâ\n",
    "\n",
    "**Should we start with Step 1: Replace the AI response calls to use your hierarchical backend API?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b091fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4517d411",
   "metadata": {},
   "source": [
    "### compare gpt.ipynb along with it\n",
    "\n",
    "generates title from question but i want the title should be generated using ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063b80e3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aff87212",
   "metadata": {},
   "source": [
    "## üìä **METRICS FOR YOUR PROJECT EVALUATION**\n",
    "\n",
    "Based on your scenario files and project goals, here are the key metrics:\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **1. CONTEXT ISOLATION METRICS** (Most Important)\n",
    "\n",
    "### **A. Keyword Precision & Recall**\n",
    "\n",
    "**Formula:**\n",
    "```python\n",
    "Precision = (Expected keywords found) / (Total expected keywords)\n",
    "Recall = (Forbidden keywords avoided) / (Total forbidden keywords)\n",
    "F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "```\n",
    "\n",
    "**Example from your test:**\n",
    "```json\n",
    "Step 7: \"How do I use loops in Python?\"\n",
    "Expected: [\"for\", \"while\", \"loop\"] ‚úÖ Found all 3 ‚Üí Precision = 100%\n",
    "Forbidden: [\"snake\", \"animal\", \"kill\", \"weapon\"] ‚úÖ Found 0 ‚Üí Recall = 100%\n",
    "F1 Score = 100%\n",
    "```\n",
    "\n",
    "**Success Threshold:**\n",
    "- ‚úÖ Precision ‚â• 80% (finds relevant keywords)\n",
    "- ‚úÖ Recall ‚â• 95% (avoids forbidden keywords)\n",
    "- üéØ **F1 Score ‚â• 87%**\n",
    "\n",
    "---\n",
    "\n",
    "### **B. Context Pollution Rate**\n",
    "\n",
    "**Formula:**\n",
    "```python\n",
    "Pollution Rate = (Steps with forbidden keywords) / (Total test steps) √ó 100%\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Total steps: 7\n",
    "Steps with pollution: 0\n",
    "Pollution Rate = 0% ‚úÖ PERFECT\n",
    "```\n",
    "\n",
    "**Success Threshold:**\n",
    "- ‚úÖ **Pollution Rate ‚â§ 5%** (industry standard)\n",
    "- üéØ **Target: 0%** (perfect isolation)\n",
    "\n",
    "---\n",
    "\n",
    "### **C. Cross-Context Leakage Score**\n",
    "\n",
    "**Measures:** How often information from one subchat appears in another\n",
    "\n",
    "```python\n",
    "Leakage Score = (Subchat messages with parent keywords) / (Total subchat messages)\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Subchat \"Python Snake Discussion\":\n",
    "- Step 4: Mentions \"snake\", \"weapon\" ‚úÖ No \"code\" or \"def\"\n",
    "- Step 5: Mentions \"eat\", \"prey\" ‚úÖ No programming terms\n",
    "Leakage Score = 0/2 = 0% ‚úÖ\n",
    "```\n",
    "\n",
    "**Success Threshold:**\n",
    "- ‚úÖ **Leakage ‚â§ 10%**\n",
    "\n",
    "---\n",
    "\n",
    "## üîç **2. RETRIEVAL ACCURACY METRICS** (RAG Performance)\n",
    "\n",
    "### **A. Retrieval Precision**\n",
    "\n",
    "**Formula:**\n",
    "```python\n",
    "Retrieval Precision = (Relevant retrieved messages) / (Total retrieved messages)\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Query: \"What programming question did I ask earlier?\"\n",
    "Retrieved 5 messages:\n",
    "- 3 about Python programming ‚úÖ Relevant\n",
    "- 2 about Python snakes ‚ùå Irrelevant\n",
    "Precision = 3/5 = 60%\n",
    "```\n",
    "\n",
    "**Success Threshold:**\n",
    "- ‚úÖ **Precision ‚â• 70%** (acceptable)\n",
    "- üéØ **Target ‚â• 85%** (good)\n",
    "\n",
    "---\n",
    "\n",
    "### **B. Retrieval Recall**\n",
    "\n",
    "**Formula:**\n",
    "```python\n",
    "Retrieval Recall = (Relevant retrieved messages) / (Total relevant messages in archive)\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Total relevant messages in archive: 5\n",
    "Retrieved relevant messages: 4\n",
    "Recall = 4/5 = 80%\n",
    "```\n",
    "\n",
    "**Success Threshold:**\n",
    "- ‚úÖ **Recall ‚â• 60%** (finds most info)\n",
    "- üéØ **Target ‚â• 80%** (comprehensive)\n",
    "\n",
    "---\n",
    "\n",
    "### **C. Mean Reciprocal Rank (MRR)**\n",
    "\n",
    "**Measures:** How quickly the system finds the right answer\n",
    "\n",
    "**Formula:**\n",
    "```python\n",
    "MRR = Average(1 / rank of first relevant result)\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Query 1: First relevant result at position 1 ‚Üí 1/1 = 1.0\n",
    "Query 2: First relevant result at position 3 ‚Üí 1/3 = 0.33\n",
    "Query 3: First relevant result at position 2 ‚Üí 1/2 = 0.5\n",
    "MRR = (1.0 + 0.33 + 0.5) / 3 = 0.61\n",
    "```\n",
    "\n",
    "**Success Threshold:**\n",
    "- ‚úÖ **MRR ‚â• 0.6** (good ranking)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° **3. SYSTEM PERFORMANCE METRICS**\n",
    "\n",
    "### **A. Response Latency**\n",
    "\n",
    "**Measures:** Time from user message to response\n",
    "\n",
    "```python\n",
    "Average Response Time = Sum(response_times) / Total_requests\n",
    "```\n",
    "\n",
    "**Breakdown:**\n",
    "- Without RAG: **< 2 seconds** ‚úÖ\n",
    "- With RAG (retrieval): **< 4 seconds** ‚úÖ\n",
    "- With long context: **< 6 seconds** ‚ö†Ô∏è\n",
    "\n",
    "**Success Threshold:**\n",
    "- ‚úÖ **95th percentile < 5 seconds**\n",
    "\n",
    "---\n",
    "\n",
    "### **B. Token Efficiency**\n",
    "\n",
    "**Measures:** How many tokens used per response\n",
    "\n",
    "```python\n",
    "Token Efficiency = Average_tokens_per_response / Context_window_size\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Response uses 500 tokens\n",
    "Context window: 8192 tokens\n",
    "Efficiency = 500/8192 = 6.1% ‚úÖ Good (not wasting tokens)\n",
    "```\n",
    "\n",
    "**Success Threshold:**\n",
    "- ‚úÖ **Efficiency < 30%** (not overusing context)\n",
    "\n",
    "---\n",
    "\n",
    "### **C. Buffer vs Archive Hit Rate**\n",
    "\n",
    "**Measures:** How often RAG is needed vs buffer is sufficient\n",
    "\n",
    "```python\n",
    "Buffer Hit Rate = (Queries answered from buffer) / (Total queries)\n",
    "Archive Hit Rate = (Queries needing RAG) / (Total queries)\n",
    "```\n",
    "\n",
    "**Success Threshold:**\n",
    "- ‚úÖ **Buffer Hit Rate ‚â• 60%** (most queries use recent context)\n",
    "- ‚úÖ **Archive Hit Rate ‚â§ 40%** (RAG is selective)\n",
    "\n",
    "---\n",
    "\n",
    "## üìà **4. TREE STRUCTURE METRICS**\n",
    "\n",
    "### **A. Average Tree Depth**\n",
    "\n",
    "**Measures:** How nested conversations get\n",
    "\n",
    "```python\n",
    "Avg Depth = Sum(depth of each conversation) / Total conversations\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Main (depth 0) ‚Üí Subchat 1 (depth 1) ‚Üí Subchat 1.1 (depth 2)\n",
    "Average Depth = (0 + 1 + 2) / 3 = 1.0\n",
    "```\n",
    "\n",
    "**Success Threshold:**\n",
    "- ‚úÖ **System supports depth ‚â• 3**\n",
    "\n",
    "---\n",
    "\n",
    "### **B. Subchat Isolation Score**\n",
    "\n",
    "**Measures:** How well subchats maintain independence\n",
    "\n",
    "```python\n",
    "Isolation Score = 1 - (Cross-subchat references / Total subchat messages)\n",
    "```\n",
    "\n",
    "**Success Threshold:**\n",
    "- ‚úÖ **Isolation Score ‚â• 0.9** (90% independent)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **5. USER EXPERIENCE METRICS** (For Paper)\n",
    "\n",
    "### **A. Context Switch Accuracy**\n",
    "\n",
    "**Measures:** Correct context after switching nodes\n",
    "\n",
    "```python\n",
    "Switch Accuracy = (Correct context after switch) / (Total switches) √ó 100%\n",
    "```\n",
    "\n",
    "**Example from your test:**\n",
    "```\n",
    "Step 6: Switch from subchat to main\n",
    "Step 7: Ask about Python loops ‚Üí Gets programming context ‚úÖ\n",
    "Accuracy = 1/1 = 100%\n",
    "```\n",
    "\n",
    "**Success Threshold:**\n",
    "- ‚úÖ **Accuracy ‚â• 95%**\n",
    "\n",
    "---\n",
    "\n",
    "### **B. Semantic Coherence Score**\n",
    "\n",
    "**Uses LLM to judge:** \"Does the response make sense given the conversation?\"\n",
    "\n",
    "```python\n",
    "Coherence = LLM_judge(response, context) # Returns 1-5 score\n",
    "Avg Coherence = Sum(coherence_scores) / Total_responses\n",
    "```\n",
    "\n",
    "**Success Threshold:**\n",
    "- ‚úÖ **Average Coherence ‚â• 4.0/5.0**\n",
    "\n",
    "---\n",
    "\n",
    "## üìä **COMPREHENSIVE METRICS TABLE**\n",
    "\n",
    "| Category | Metric | Formula | Target | Critical? |\n",
    "|----------|--------|---------|--------|-----------|\n",
    "| **Context Isolation** | Precision | Expected found / Total expected | ‚â•80% | ‚≠ê‚≠ê‚≠ê |\n",
    "| | Recall | Forbidden avoided / Total forbidden | ‚â•95% | ‚≠ê‚≠ê‚≠ê |\n",
    "| | Pollution Rate | Polluted steps / Total steps | ‚â§5% | ‚≠ê‚≠ê‚≠ê |\n",
    "| | F1 Score | 2PR/(P+R) | ‚â•87% | ‚≠ê‚≠ê‚≠ê |\n",
    "| **RAG Performance** | Retrieval Precision | Relevant / Retrieved | ‚â•70% | ‚≠ê‚≠ê |\n",
    "| | Retrieval Recall | Retrieved / Total relevant | ‚â•60% | ‚≠ê‚≠ê |\n",
    "| | MRR | Avg(1/rank) | ‚â•0.6 | ‚≠ê |\n",
    "| **Performance** | Response Time | Avg latency | <5s | ‚≠ê‚≠ê |\n",
    "| | Token Efficiency | Tokens used / Window | <30% | ‚≠ê |\n",
    "| **Tree Structure** | Isolation Score | 1 - Cross-refs | ‚â•0.9 | ‚≠ê‚≠ê |\n",
    "| | Switch Accuracy | Correct / Total switches | ‚â•95% | ‚≠ê‚≠ê‚≠ê |\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **RECOMMENDED METRICS FOR YOUR PAPER**\n",
    "\n",
    "### **Primary Metrics** (Must report):\n",
    "1. ‚úÖ **Context Isolation F1 Score** (most important)\n",
    "2. ‚úÖ **Pollution Rate** (safety critical)\n",
    "3. ‚úÖ **Retrieval Precision** (RAG quality)\n",
    "4. ‚úÖ **Switch Accuracy** (tree navigation)\n",
    "\n",
    "### **Secondary Metrics** (Good to have):\n",
    "5. ‚úÖ Response Latency\n",
    "6. ‚úÖ Buffer Hit Rate\n",
    "7. ‚úÖ Tree Depth Support\n",
    "\n",
    "### **Optional Metrics** (If time permits):\n",
    "8. Token Efficiency\n",
    "9. MRR\n",
    "10. Coherence Score\n",
    "\n",
    "---\n",
    "\n",
    "## üìù **HOW TO REPORT IN PAPER**\n",
    "\n",
    "```markdown\n",
    "## Experimental Results\n",
    "\n",
    "### Context Isolation Performance\n",
    "- **F1 Score**: 94.2% (Precision: 91%, Recall: 97.5%)\n",
    "- **Pollution Rate**: 2.1% (below 5% threshold)\n",
    "- **Cross-Context Leakage**: 0% (perfect isolation)\n",
    "\n",
    "### Retrieval Accuracy\n",
    "- **Precision**: 82.3% (exceeds 70% target)\n",
    "- **Recall**: 73.1% (exceeds 60% target)\n",
    "- **MRR**: 0.68 (good ranking)\n",
    "\n",
    "### System Performance\n",
    "- **Average Response Time**: 3.2s (within 5s target)\n",
    "- **Context Switch Accuracy**: 98.7%\n",
    "- **Tree Depth Support**: Successfully tested up to depth 4\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to run the tests and collect these metrics?** Your existing [`backend/dataset/run_dataset.py`](backend/dataset/run_dataset.py ) already calculates most of these! üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
